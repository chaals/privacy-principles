# TAG Privacy TF Call - 22 November 2023

Present: Dan, Don, Jeffrey, Sam, Pete, Amy, Nick

## [Ancillary Data](https://github.com/w3ctag/privacy-principles/pull/361)

Jeffrey: I see that pete is ok with this change

Pete: yes I agree to merge.  I'd like to take the conversation in the broader conversation... 

Dan: can we merge this and continue that discussion?

Pete: either way I think the text in the PR is Ok...

Dan: <leaves comment saying we've agreed to merge.>

Jeffrey: close 221?

Dan: yes.

Pete: does this close 220? *reviews*

Jeffrey: feel free to re-open it off-line.

## user intent

Peter: my original concern was - uncomfortable with "ancillary data" as def we have now... ancillary - it's ancillary because it's there for some other reason that achieving a user goal.  Making another plea to that.

Jeffrey: I think Yoav's point is - it makse sense to distinguish data that is for a user need vs data for a site's need - but doesn't make sense to distinguish APIs that way... If we can block the data itself because it's not for the user's direct benefit then it's fine... 

Peter: a clearer way would to be say "some APIs are for ancillary purposes, some are for user purposes" - 

Jeffrey: I think the disagreement is about whether the api is critical or the data is critical

Dan: the other piece is about whether or not we want to compel that platforms should always ask when they want to send usage data, ancilliary data, telemetry data to the application developer. I have the feeling that people are frustrated because I keep simplifying this... even though it's a complex question (sorry) however ... the other day I left feedback after a bad video call and it asked if I wanted to attach diagnostic data to the feedback, and I was happy to. This is what I'm talking about with asking users consent to convey ancilliary data. Why is it necessary to do it in that case, but not for the browser to do it, for the browser to act as an intermediary to request the users consent for a third party to get that data. Which is arguably even more problematic. I'm uncomfortable with making the statement that because web perf data can be obtained via other means (such as use of dom apis) that therefore it is better to not ask permission because some people might say no, and therefore developers might use this other way of getting this information.. I'm not comfortable with that. I still feel we need to be stronger in this document, or highlight the disagreement more or something.

Nick: why did we merge the PR?

Dan: it's better... the PR has the text

Jeffrey: the PR makes it easier to make that shift. We could change the text to adopt Dan's suggestion is smaller than it would have been with the previous state

Dan: the text has the bit in it about the TF is not at consensus about how UAs should handle ancilliary data

Nick: it just also changed it so that preivously we said users should be able to turn off ancilliary apis, whereas now it says they should turn off a subset..

Dan: we didn't have consensus on what users should be able to turn off.. Do we have consensus that ancilliary apis that add new information, the user should always be asked?

Pete: +1

Jeffrey: even if it doesn't expose personal data, they should still be asked about sending anything?

Don: I agree. We have to be careful. Not doing it behind the user's back

Dan: the arguement with ancilliary apis computed from existing information is quite clear - it's an easier way to get information that is already existing. Sympathetic to argument that if you can get the information in a more performant way using a for-purpose api it's better, potentially for privacy as well because if you're a privacy focussed browser you know which things to not implement or block in high privacy mode. But in the case of things that are new telemetry information maybe we do need to have a stronger wording.

Jeffrey: still skeptical. We should run it by wgs that would be affected. I doubt chrome would implement it the first run question, especially not inline questions. The example of debugging information - totally reasonable to ask consent inline for a debugging api, I'd lovle to have one of those. But that's not this class of information .. it's a piece, but not the stuff that web perf is worried about.

Dan: we could end up with something .. we have mostly SHOULDs.. might be appropriate to have language that says browsers should request sharing this kind of ancilliary data, especially if they are concerned about users privacy... should treat these apis differently in a high privacy mode. Should consider turning them off if the user is in private browsing mode.

Jeffrey: yeah. We have the principle about disabling them. We could tweak that. UAs should something about set the enabledness of the apis based on their impression of the users intent. That doesn't say what the default should be.

*tweaking text*

Pete: 'new' on what baseline... different word? Intended to mean not planned for removal?

Jeffrey: right

Dan: [creates issue 372](https://github.com/w3ctag/privacy-principles/issues/372)

## https://github.com/w3ctag/privacy-principles/pull/369

*reviewing*

*discussion of definition of a vulnerable person when it comes to this document*

Don: it's contextual

Pete: we need this why?

Jeffrey: 1, 2.9

*discussion of whether we can simply remove this*

Amy: i am worried it would not hurt to remind people that not everyone is the same is them...

Pete: I agree but defining 'vulnerable' might not be the right way...

Jeffrey: punt this to an issue?

Nick: I think it's a better definition...  we should be consistent.

*discussion of whether to ditch the vegas rule*

Don: better to look at context .. rather than the vegas rule. I agree with taking it out.

## 370

*Jeffrey to reply and close*

Don: some of the threat models that get lumped together with privacy are threats to personalization ... infering that a person has a disability and then not showing them a particular job listing would be a personalization risk .. 

Jeffrey: privacy can be about the misuse of data about someone that they feel are invasive...  To remove the violation they would have had to intend for that data to be used that way...

Dan: Kind of agree with that...

Jeffrey: back when gmail scanned emails to target ads...

Don: we can say that it's a privacy risk even if it's personalization that happens in a way where no other party is aware of it.

Jeffrey: yes - it can still be a privacy harm.

Don: makes it easier to think about threat models... e.g. "this user was prevented from seeing this content in some way"







